# SQLAlchemy 2.0 åŸºæœ¬è¨­å®š

SQLAlchemy 2.0ã«ãŠã‘ã‚‹åŸºæœ¬çš„ãªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ‘ã‚¿ãƒ¼ãƒ³ã€‚éåŒæœŸã‚¨ãƒ³ã‚¸ãƒ³ã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®šã€ã‚«ã‚¹ã‚¿ãƒ å‹å®šç¾©ã‚’ä¸­å¿ƒã¨ã—ãŸå®Ÿè£…æŒ‡é‡ã€‚

## ğŸ”§ SQLAlchemy 2.0 åŸºæœ¬è¨­å®š

### éåŒæœŸã‚¨ãƒ³ã‚¸ãƒ³ã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³è¨­å®š

```python
# database/config.py
from sqlalchemy.ext.asyncio import (
    create_async_engine, 
    AsyncSession, 
    async_sessionmaker,
    AsyncEngine
)
from sqlalchemy.orm import DeclarativeBase, MappedAsDataclass
from sqlalchemy.pool import NullPool, QueuePool
from sqlalchemy import event, text
from contextlib import asynccontextmanager
from typing import AsyncGenerator, Optional
import logging

from config.settings import settings


class Base(MappedAsDataclass, DeclarativeBase):
    """
    SQLAlchemy 2.0 ã‚¹ã‚¿ã‚¤ãƒ«ã®ãƒ™ãƒ¼ã‚¹ã‚¯ãƒ©ã‚¹
    MappedAsDataclassã‚’ä½¿ç”¨ã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹æ©Ÿèƒ½ã‚’æä¾›
    """
    pass


class DatabaseManager:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã¨ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†"""
    
    def __init__(self):
        self.engine: Optional[AsyncEngine] = None
        self.session_factory: Optional[async_sessionmaker[AsyncSession]] = None
        
    async def initialize(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""
        # éåŒæœŸã‚¨ãƒ³ã‚¸ãƒ³ä½œæˆ
        if settings.ENVIRONMENT == "test":
            # ãƒ†ã‚¹ãƒˆç’°å¢ƒ: ã‚¤ãƒ³ãƒ¡ãƒ¢ãƒªã¾ãŸã¯ä¸€æ™‚çš„ãªæ¥ç¶š
            self.engine = create_async_engine(
                settings.DATABASE_URL,
                echo=settings.DATABASE_ECHO,
                poolclass=NullPool,  # ãƒ†ã‚¹ãƒˆæ™‚ã¯æ¥ç¶šãƒ—ãƒ¼ãƒ«ã‚’ç„¡åŠ¹åŒ–
                isolation_level="AUTOCOMMIT",
            )
        else:
            # ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç’°å¢ƒ: æœ€é©åŒ–ã•ã‚ŒãŸæ¥ç¶šãƒ—ãƒ¼ãƒ«
            self.engine = create_async_engine(
                settings.DATABASE_URL,
                echo=settings.DATABASE_ECHO,
                poolclass=QueuePool,
                pool_size=settings.DATABASE_POOL_SIZE,
                max_overflow=settings.DATABASE_MAX_OVERFLOW,
                pool_timeout=settings.DATABASE_POOL_TIMEOUT,
                pool_pre_ping=True,  # æ¥ç¶šã®å¥å…¨æ€§ãƒã‚§ãƒƒã‚¯
                pool_recycle=3600,   # 1æ™‚é–“ã§æ¥ç¶šã‚’ãƒªã‚µã‚¤ã‚¯ãƒ«
                connect_args={
                    "command_timeout": 60,
                    "server_settings": {
                        "application_name": settings.APP_NAME,
                        "jit": "off",  # JITã‚’ç„¡åŠ¹åŒ–ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
                    }
                }
            )
        
        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¯ãƒˆãƒªãƒ¼ä½œæˆ
        self.session_factory = async_sessionmaker(
            bind=self.engine,
            class_=AsyncSession,
            expire_on_commit=False,  # ã‚³ãƒŸãƒƒãƒˆå¾Œã‚‚ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½¿ç”¨å¯èƒ½
            autoflush=True,          # è‡ªå‹•ãƒ•ãƒ©ãƒƒã‚·ãƒ¥æœ‰åŠ¹
            autocommit=False,        # è‡ªå‹•ã‚³ãƒŸãƒƒãƒˆç„¡åŠ¹
        )
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ
        await self._test_connection()
        
        # ã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼è¨­å®š
        self._setup_event_listeners()
        
        logging.info("Database initialized successfully")
    
    async def _test_connection(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ"""
        try:
            async with self.engine.begin() as conn:
                await conn.execute(text("SELECT 1"))
            logging.info("Database connection test successful")
        except Exception as e:
            logging.error(f"Database connection failed: {e}")
            raise
    
    def _setup_event_listeners(self):
        """SQLAlchemyã‚¤ãƒ™ãƒ³ãƒˆãƒªã‚¹ãƒŠãƒ¼è¨­å®š"""
        
        @event.listens_for(self.engine.sync_engine, "connect")
        def set_postgresql_options(dbapi_connection, connection_record):
            """PostgreSQLæœ€é©åŒ–è¨­å®š"""
            if "postgresql" in settings.DATABASE_URL:
                with dbapi_connection.cursor() as cursor:
                    # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³è¨­å®š
                    cursor.execute("SET timezone TO 'UTC'")
                    # åˆ†é›¢ãƒ¬ãƒ™ãƒ«è¨­å®š
                    cursor.execute("SET default_transaction_isolation TO 'read committed'")
                    # çµ±è¨ˆæƒ…å ±æ›´æ–°
                    cursor.execute("SET track_counts TO on")
                    cursor.execute("SET track_io_timing TO on")
        
        @event.listens_for(AsyncSession, "before_bulk_insert")
        def receive_before_bulk_insert(query, query_context, result):
            """ãƒãƒ«ã‚¯ã‚¤ãƒ³ã‚µãƒ¼ãƒˆå‰ã®ãƒ­ã‚°"""
            logging.info(f"Bulk insert starting: {query}")
        
        @event.listens_for(AsyncSession, "after_transaction_end")
        def receive_after_transaction_end(session, transaction):
            """ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³çµ‚äº†å¾Œã®ãƒ­ã‚°"""
            if transaction.is_active:
                logging.debug("Transaction committed successfully")
    
    @asynccontextmanager
    async def get_session(self) -> AsyncGenerator[AsyncSession, None]:
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³å–å¾—ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ï¼‰"""
        if not self.session_factory:
            raise RuntimeError("Database not initialized")
        
        async with self.session_factory() as session:
            try:
                yield session
            except Exception:
                await session.rollback()
                raise
            finally:
                await session.close()
    
    async def create_tables(self):
        """ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ"""
        async with self.engine.begin() as conn:
            await conn.run_sync(Base.metadata.create_all)
        logging.info("Tables created successfully")
    
    async def drop_tables(self):
        """ãƒ†ãƒ¼ãƒ–ãƒ«å‰Šé™¤"""
        async with self.engine.begin() as conn:
            await conn.run_sync(Base.metadata.drop_all)
        logging.info("Tables dropped successfully")
    
    async def close(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šçµ‚äº†"""
        if self.engine:
            await self.engine.dispose()
        logging.info("Database connections closed")


# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
db_manager = DatabaseManager()


# ä¾å­˜æ€§æ³¨å…¥ç”¨
async def get_async_session() -> AsyncGenerator[AsyncSession, None]:
    """FastAPIä¾å­˜æ€§æ³¨å…¥ç”¨ã‚»ãƒƒã‚·ãƒ§ãƒ³å–å¾—"""
    async with db_manager.get_session() as session:
        yield session
```

### ã‚«ã‚¹ã‚¿ãƒ å‹å®šç¾©

```python
# database/types.py
from sqlalchemy import TypeDecorator, String, Text
from sqlalchemy.dialects.postgresql import UUID, JSONB, ARRAY
from typing import Any, Optional, Dict, List
import json
import uuid


class GUID(TypeDecorator):
    """ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ç‹¬ç«‹ãªGUIDå‹"""
    impl = String
    cache_ok = True
    
    def load_dialect_impl(self, dialect):
        if dialect.name == 'postgresql':
            return dialect.type_descriptor(UUID())
        else:
            return dialect.type_descriptor(String(36))
    
    def process_bind_param(self, value, dialect):
        if value is None:
            return value
        elif dialect.name == 'postgresql':
            return str(value)
        else:
            if not isinstance(value, uuid.UUID):
                return str(uuid.UUID(value))
            return str(value)
    
    def process_result_value(self, value, dialect):
        if value is None:
            return value
        else:
            if not isinstance(value, uuid.UUID):
                return uuid.UUID(value)
            return value


class JSONType(TypeDecorator):
    """ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ç‹¬ç«‹ãªJSONå‹"""
    impl = Text
    cache_ok = True
    
    def load_dialect_impl(self, dialect):
        if dialect.name == 'postgresql':
            return dialect.type_descriptor(JSONB())
        else:
            return dialect.type_descriptor(Text())
    
    def process_bind_param(self, value, dialect):
        if value is None:
            return value
        if dialect.name == 'postgresql':
            return value
        else:
            return json.dumps(value)
    
    def process_result_value(self, value, dialect):
        if value is None:
            return value
        if dialect.name == 'postgresql':
            return value
        else:
            return json.loads(value)


class ArrayType(TypeDecorator):
    """ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ç‹¬ç«‹ãªé…åˆ—å‹"""
    impl = Text
    cache_ok = True
    
    def __init__(self, item_type=String):
        self.item_type = item_type
        super().__init__()
    
    def load_dialect_impl(self, dialect):
        if dialect.name == 'postgresql':
            return dialect.type_descriptor(ARRAY(self.item_type))
        else:
            return dialect.type_descriptor(Text())
    
    def process_bind_param(self, value, dialect):
        if value is None:
            return value
        if dialect.name == 'postgresql':
            return value
        else:
            return json.dumps(value)
    
    def process_result_value(self, value, dialect):
        if value is None:
            return value
        if dialect.name == 'postgresql':
            return value
        else:
            return json.loads(value)
```

## ğŸ”§ æ¥ç¶šãƒ—ãƒ¼ãƒ«æœ€é©åŒ–

### ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç’°å¢ƒã®æ¥ç¶šãƒ—ãƒ¼ãƒ«è¨­å®š

```python
# config/database_settings.py
from pydantic import BaseSettings
from typing import Optional

class DatabaseSettings(BaseSettings):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š"""
    DATABASE_URL: str
    DATABASE_ECHO: bool = False
    DATABASE_POOL_SIZE: int = 10
    DATABASE_MAX_OVERFLOW: int = 20
    DATABASE_POOL_TIMEOUT: int = 30
    DATABASE_POOL_RECYCLE: int = 3600
    DATABASE_POOL_PRE_PING: bool = True
    
    # é«˜è² è·ç’°å¢ƒã§ã®è¨­å®š
    DATABASE_CONNECT_TIMEOUT: int = 60
    DATABASE_COMMAND_TIMEOUT: int = 60
    
    class Config:
        env_file = ".env"


# ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³æœ€é©åŒ–ã‚¨ãƒ³ã‚¸ãƒ³
def create_optimized_engine(settings: DatabaseSettings):
    """é«˜æ€§èƒ½ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³ç’°å¢ƒç”¨ã‚¨ãƒ³ã‚¸ãƒ³"""
    return create_async_engine(
        settings.DATABASE_URL,
        echo=settings.DATABASE_ECHO,
        poolclass=QueuePool,
        pool_size=settings.DATABASE_POOL_SIZE,
        max_overflow=settings.DATABASE_MAX_OVERFLOW,
        pool_timeout=settings.DATABASE_POOL_TIMEOUT,
        pool_recycle=settings.DATABASE_POOL_RECYCLE,
        pool_pre_ping=settings.DATABASE_POOL_PRE_PING,
        # PostgreSQLå›ºæœ‰ã®æœ€é©åŒ–
        connect_args={
            "command_timeout": settings.DATABASE_COMMAND_TIMEOUT,
            "server_settings": {
                "application_name": "MyApp",
                "tcp_keepalives_idle": "600",
                "tcp_keepalives_interval": "30",
                "tcp_keepalives_count": "3",
            }
        },
        # éåŒæœŸå‡¦ç†æœ€é©åŒ–
        execution_options={
            "isolation_level": "READ_COMMITTED",
            "autocommit": False,
        }
    )
```

## ğŸ“Š ç›£è¦–ã¨ãƒ­ã‚®ãƒ³ã‚°

### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç›£è¦–

```python
# monitoring/database_monitor.py
import time
import logging
from sqlalchemy import event
from sqlalchemy.engine import Engine
from sqlalchemy.pool import Pool

logger = logging.getLogger(__name__)

class DatabaseMonitor:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šç›£è¦–"""
    
    def __init__(self):
        self.connection_count = 0
        self.query_count = 0
        self.slow_query_threshold = 1.0  # 1ç§’
    
    def setup_monitoring(self, engine: Engine):
        """ç›£è¦–è¨­å®š"""
        
        @event.listens_for(Pool, "connect")
        def receive_connect(dbapi_connection, connection_record):
            """æ¥ç¶šæ™‚ã®ç›£è¦–"""
            self.connection_count += 1
            logger.info(f"Database connection established. Total: {self.connection_count}")
        
        @event.listens_for(Pool, "checkout")
        def receive_checkout(dbapi_connection, connection_record, connection_proxy):
            """æ¥ç¶šãƒã‚§ãƒƒã‚¯ã‚¢ã‚¦ãƒˆæ™‚ã®ç›£è¦–"""
            logger.debug("Connection checked out from pool")
        
        @event.listens_for(Pool, "checkin")
        def receive_checkin(dbapi_connection, connection_record):
            """æ¥ç¶šãƒã‚§ãƒƒã‚¯ã‚¤ãƒ³æ™‚ã®ç›£è¦–"""
            logger.debug("Connection checked in to pool")
        
        @event.listens_for(Engine, "before_cursor_execute")
        def receive_before_cursor_execute(conn, cursor, statement, parameters, context, executemany):
            """ã‚¯ã‚¨ãƒªå®Ÿè¡Œå‰ã®ç›£è¦–"""
            context._query_start_time = time.time()
            self.query_count += 1
        
        @event.listens_for(Engine, "after_cursor_execute")
        def receive_after_cursor_execute(conn, cursor, statement, parameters, context, executemany):
            """ã‚¯ã‚¨ãƒªå®Ÿè¡Œå¾Œã®ç›£è¦–"""
            total = time.time() - context._query_start_time
            if total > self.slow_query_threshold:
                logger.warning(f"Slow query detected: {total:.2f}s - {statement[:100]}")
            logger.debug(f"Query executed in {total:.3f}s")


# ä½¿ç”¨ä¾‹
monitor = DatabaseMonitor()
monitor.setup_monitoring(engine)
```

## ğŸš€ å®Ÿè£…ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### 1. éåŒæœŸã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†

```python
# repository/base.py
from abc import ABC, abstractmethod
from typing import Generic, TypeVar, Type, Optional, List
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, update, delete
from sqlalchemy.exc import SQLAlchemyError

T = TypeVar('T')

class AsyncRepository(Generic[T], ABC):
    """éåŒæœŸãƒªãƒã‚¸ãƒˆãƒªåŸºåº•ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, session: AsyncSession, model_class: Type[T]):
        self.session = session
        self.model_class = model_class
    
    async def get_by_id(self, id: int) -> Optional[T]:
        """IDã«ã‚ˆã‚‹å–å¾—"""
        try:
            result = await self.session.execute(
                select(self.model_class).where(self.model_class.id == id)
            )
            return result.scalar_one_or_none()
        except SQLAlchemyError as e:
            logger.error(f"Error fetching {self.model_class.__name__} by id {id}: {e}")
            raise
    
    async def create(self, entity: T) -> T:
        """ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£ä½œæˆ"""
        try:
            self.session.add(entity)
            await self.session.flush()
            await self.session.refresh(entity)
            return entity
        except SQLAlchemyError as e:
            logger.error(f"Error creating {self.model_class.__name__}: {e}")
            await self.session.rollback()
            raise
    
    async def update(self, entity: T) -> T:
        """ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£æ›´æ–°"""
        try:
            await self.session.merge(entity)
            await self.session.flush()
            await self.session.refresh(entity)
            return entity
        except SQLAlchemyError as e:
            logger.error(f"Error updating {self.model_class.__name__}: {e}")
            await self.session.rollback()
            raise
    
    async def delete(self, id: int) -> bool:
        """ã‚¨ãƒ³ãƒ†ã‚£ãƒ†ã‚£å‰Šé™¤"""
        try:
            result = await self.session.execute(
                delete(self.model_class).where(self.model_class.id == id)
            )
            return result.rowcount > 0
        except SQLAlchemyError as e:
            logger.error(f"Error deleting {self.model_class.__name__} with id {id}: {e}")
            await self.session.rollback()
            raise
```

### 2. ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ç®¡ç†

```python
# services/base.py
from contextlib import asynccontextmanager
from typing import AsyncGenerator
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.exc import SQLAlchemyError
import logging

logger = logging.getLogger(__name__)

class TransactionManager:
    """ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ç®¡ç†"""
    
    def __init__(self, db_manager):
        self.db_manager = db_manager
    
    @asynccontextmanager
    async def transaction(self) -> AsyncGenerator[AsyncSession, None]:
        """ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ç®¡ç†ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ"""
        async with self.db_manager.get_session() as session:
            try:
                await session.begin()
                yield session
                await session.commit()
                logger.debug("Transaction committed successfully")
            except SQLAlchemyError as e:
                await session.rollback()
                logger.error(f"Transaction rolled back due to error: {e}")
                raise
            except Exception as e:
                await session.rollback()
                logger.error(f"Transaction rolled back due to unexpected error: {e}")
                raise

# ä½¿ç”¨ä¾‹
async def transfer_funds(transaction_manager, from_account_id, to_account_id, amount):
    """è³‡é‡‘ç§»å‹•ï¼ˆãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ä¾‹ï¼‰"""
    async with transaction_manager.transaction() as session:
        # è¤‡æ•°ã®æ“ä½œã‚’åŒä¸€ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³å†…ã§å®Ÿè¡Œ
        from_account = await account_repo.get_by_id(from_account_id)
        to_account = await account_repo.get_by_id(to_account_id)
        
        from_account.balance -= amount
        to_account.balance += amount
        
        await session.flush()  # åˆ¶ç´„ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ
        # ã‚³ãƒŸãƒƒãƒˆã¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ãŒè‡ªå‹•å®Ÿè¡Œ
```